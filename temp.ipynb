{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\n",
      "2 AOSLO-net_ a deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscopy images\n",
      "3 Artificial intelligence velocimetry and microaneurysm-on-a-chip for three-dimensional analysis of blood flow in physiology and disease\n",
      "4 Computational investigation of blood cell transport in retinal microaneurysms\n",
      "5 Deep-PIV_ A new framework of PIV using deep learning techniques\n",
      "6 DeepM&Mnet_ Inferring the electroconvection multiphysics fields based on operator approximation by neural networks\n",
      "7 DeepPTV_ particle tracking velocimetry for complex flow motion via deep neural networks\n",
      "8 Dense motion estimation of particle images via a convolutional neural network\n",
      "9 Dynamic illumination optical flow computing for sensing multiple mobile robots from a drone\n",
      "10 Ensemble-Variational methods in data assimilation\n",
      "11 Filtering enhanced tomographic PIV reconstruction based on deep neural networks\n",
      "12 Flow over an espresso cup_ inferring 3-D velocity and pressure fields from tomographic background oriented Schlieren via physics-informed neural networks\n",
      "13 Forecasting solar-thermal systems performance under transient operation using a data-driven machine learning approach based on the deep operator network architecture\n",
      "14 Heat transfer prediction with unknown thermal boundary conditions using physics-informed neural networks\n",
      "15 Motion estimation under location uncertainty for turbulent fluid flows\n",
      "16 Neural observer with Lyapunov stability guarantee for uncertain nonlinear systems\n",
      "17 NSFnets (Navier-Stokes flow nets)_ Physics-informed neural networks for the incompressible Navier-Stokes equations\n",
      "18 Operator learning for predicting multiscale bubble growth dynamics\n",
      "19 Particle image velocimetry based on a deep learning motion estimator\n",
      "20 Particle image velocimetry based on a deep neural network\n",
      "21 Physics-informed neural networks (PINNs) for fluid mechanics_ A review\n",
      "22 Physics-informed neural networks for heat transfer problems\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "for root, dirs, files in os.walk('cai_teacher_articles'):\n",
    "    # for file_name in files:\n",
    "    #     print(file_name)\n",
    "    #     file_path = os.path.join(root, file_name)\n",
    "    #     print(file_path)  # 打印文件路径\n",
    "    for idx_dir , dir in enumerate(dirs):\n",
    "        print(f'{idx_dir+1} {dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recurrent graph optimal transport for learning 3D flow motion in particle tracking.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果勾选了自动下载PDF，根据链接自动下载PDF\n",
    "if self.checkBoxDownloadPDF.isChecked():\n",
    "    article_list = PDFDownload.read_file(file_path)\n",
    "    # self.textEditLog.append('开始下载文件！共有{}项需要下载。'.format(len(article_list)))\n",
    "    PDFDownload.download_file(self, article_list, pdfSavePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request    # 用于网络连接，即PDF下载\n",
    "import os    # 用于文件操作，例如删除、重命名\n",
    "import pandas as pd    # 用于Excel读取及Dataframe转换\n",
    "from copy import deepcopy    # 用于字典的深拷贝\n",
    "from retrying import retry    # 用于下载错误重试\n",
    "import gc    # 用于解决内存泄漏 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PDFDownload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = {\n",
    "    'Title':'A physics-informed variational DeepONet for predicting crack path in quasi-brittle materials',\n",
    "    'PDF Link' : 'https://www.sciencedirect.com/science/article/am/pii/S004578252200010X'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始下载https://proceedings.neurips.cc/paper_files/paper/2022/file/948552777302d3abf92415b1d7e9de70-Paper-Conference.pdf\n",
      "./Physics-informed neural operators.pdf\n",
      "Sucessful to download /Physics-informed neural operators\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\n",
    "    'Title':'Physics-informed neural operators',\n",
    "    # 'PDF Link' : 'https://arxiv.org/pdf/2207.05748'\n",
    "    # 'PDF Link' : 'https://www.jmlr.org/papers/volume23/22-0297/22-0297.pdf'\n",
    "    'PDF Link' : 'https://proceedings.neurips.cc/paper_files/paper/2022/file/948552777302d3abf92415b1d7e9de70-Paper-Conference.pdf'\n",
    "    # 'PDF Link' : 'https://www.researchgate.net/profile/Somdatta-Goswami/publication/374438071_Physics-Informed_Deep_Neural_Operator_Networks/links/6522de97b0df2f20a21d63b4/Physics-Informed-Deep-Neural-Operator-Networks.pdf'\n",
    "}\n",
    "\n",
    "# PDFDownload.get_file(article_list,path='.')\n",
    "PDFDownload.get_file(a,path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_host' from 'urllib3.util.url' (d:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\urllib3\\util\\url.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12120\\762338720.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     '''\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\selenium\\webdriver\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# under the License.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfirefox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWebDriver\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mFirefox\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfirefox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirefox_profile\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFirefoxProfile\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfirefox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mFirefoxOptions\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\selenium\\webdriver\\firefox\\webdriver.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesired_capabilities\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDesiredCapabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWebDriver\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mRemoteWebDriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mextension_connection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExtensionConnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCommand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mwebelement\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mremote_connection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRemoteConnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0merrorhandler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mErrorHandler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mswitch_to\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSwitchTo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0murllib3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\urllib3\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretry\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRetry\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_host\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0m__author__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Andrey Petrov (andrey.petrov@shazow.net)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_host' from 'urllib3.util.url' (d:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\urllib3\\util\\url.py)"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "def get_file(article, path):\n",
    "    '''\n",
    "    :Description:\n",
    "    :Parameter  : article :文章名字以及下载链接\n",
    "                  path： 保存pdf文件的路径\n",
    "    :Return     :\n",
    "    '''\n",
    "    filename = '/' + article['Title']\n",
    "    url = article['PDF Link']\n",
    "    print('开始下载' + url)\n",
    "    \n",
    "    # 初始化浏览器\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--ignore-ssl-errors')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    # 打开链接\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # 等待页面加载完全\n",
    "    except Exception as e:\n",
    "        print('URL打开失败，继续下载下一个。')\n",
    "        print(e)\n",
    "        driver.quit()\n",
    "        return article\n",
    "    \n",
    "    # 下载文件\n",
    "    try:\n",
    "        # 这里根据网站的具体情况，可能需要点击一些按钮或者填写一些表单\n",
    "        # 如果有人机验证，通常会弹出验证码，需要处理验证码\n",
    "        # 处理验证码的方法也因网站而异，可能需要手动输入验证码，也可能需要借助第三方识别服务\n",
    "        \n",
    "        # 这里仅演示简单的下载操作，具体需要根据网站的实际情况进行修改\n",
    "        with open(path + filename + '.pdf', 'wb') as f:\n",
    "            f.write(driver.page_source.encode('utf-8'))\n",
    "        print(path + filename + '.pdf')\n",
    "        print(\"Sucessful to download\" + \" \" + filename)\n",
    "    except Exception as e:\n",
    "        print('下载出错，继续下载下一个。')\n",
    "        print(e)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 调用函数并传入参数\n",
    "\n",
    "get_file(article_list,path='.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12120\\3306587225.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marticle_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.xls'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12120\\3306587225.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 读取要下载的PDF列表\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# 读取Excel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m# print(dataframe)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m# 读取行数\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0munnumbered\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0momit\u001b[0m \u001b[0moffsets\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mfor\u001b[0m \u001b[0mmeaningful\u001b[0m \u001b[0mdiffs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \"\"\"\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbiffh\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbiff_dump\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[0mbk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mbk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiff2_8_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "# 读取要下载的PDF列表\n",
    "def read_file(filename):\n",
    "    # dataframe = pd.read_excel(filename)    # 读取Excel\n",
    "b    excel_data = pd.ExcelFile(filename)\n",
    "    sheet_data = pd.read_excel(excel_data,'Sheet1')\n",
    "    for index,row in sheet_data.iterrows():\n",
    "        \n",
    "\n",
    "\n",
    "    # print(dataframe)\n",
    "    rows = dataframe.shape[0]    # 读取行数\n",
    "    # print(rows)\n",
    "    # 提取Title、Journal、Authors、Year、Citation、Abstract、PDF Link， 并抓换为list\n",
    "    article_list = []\n",
    "    for i in range(rows):\n",
    "        title = str(dataframe.iat[i, 0])\n",
    "        title.replace('\\n', '')\n",
    "        title.replace('\\r', '')\n",
    "        pdf_link = str(dataframe.iat[i, 1])\n",
    "        # journal = str(dataframe.iat[i, 1])\n",
    "        # authors = str(dataframe.iat[i, 2])\n",
    "        # year = str(dataframe.iat[i, 3])\n",
    "        # citation = str(dataframe.iat[i, 4])\n",
    "        # abstract = str(dataframe.iat[i, 5])\n",
    "        print(title + ' '+pdf_link)\n",
    "        # article_dict = {'Title': title, 'Journal': str(dataframe.iat[i, 1]), 'Authors': str(dataframe.iat[i, 2]), \n",
    "        #                 'Year': str(dataframe.iat[i, 3]), 'Citation': str(dataframe.iat[i, 4]), 'Abstract': str(dataframe.iat[i, 5]), \n",
    "        #                 \"PDF Link\": str(dataframe.iat[i, 6])}\n",
    "        article_dict = {'Title': title, \"PDF Link\": str(dataframe.iat[i, 1])}\n",
    "        article_list.append(article_dict)\n",
    "    # print(len(article_list))\n",
    "    del dataframe\n",
    "    del rows\n",
    "    del title\n",
    "    del article_dict\n",
    "    gc.collect()\n",
    "    return article_list\n",
    "\n",
    "read_file(r'cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12120\\887200621.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.xlsx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexcel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msheet_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexcel_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Sheet1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msheet_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n",
      "\u001b[1;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "filename = r'cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.xlsx'\n",
    "excel_data = pd.ExcelFile(filename)\n",
    "sheet_data = pd.read_excel(excel_data,'Sheet1')\n",
    "for index,row in sheet_data.iterrows():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "Excel xlsx file; not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12120\\2868535626.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# data = pd.read_excel('abc.xlsx',engine='openpyxl')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mold_arg_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mnew_arg_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                     msg = (\n\u001b[0;32m    180\u001b[0m                         \u001b[1;34mf\"the {repr(old_arg_name)} keyword is deprecated and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mold_arg_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mnew_arg_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m                     msg = (\n\u001b[0;32m    180\u001b[0m                         \u001b[1;34mf\"the {repr(old_arg_name)} keyword is deprecated and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows, ignore_workbook_corruption)\u001b[0m\n",
      "\u001b[1;31mXLRDError\u001b[0m: Excel xlsx file; not supported"
     ]
    }
   ],
   "source": [
    "pd.read_excel(r'cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.xlsx')\n",
    "# data = pd.read_excel('abc.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a ='Physics-informed neural networks (PINNs) for fluid mechanics_ A review.txt'\n",
    "a.endswith('.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.xls to cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\AOSLO-net_ a deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscopy images\\pdf_link_result.xls to cai_teacher_articles\\AOSLO-net_ a deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscopy images\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Artificial intelligence velocimetry and microaneurysm-on-a-chip for three-dimensional analysis of blood flow in physiology and disease\\pdf_link_result.xls to cai_teacher_articles\\Artificial intelligence velocimetry and microaneurysm-on-a-chip for three-dimensional analysis of blood flow in physiology and disease\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Computational investigation of blood cell transport in retinal microaneurysms\\pdf_link_result.xls to cai_teacher_articles\\Computational investigation of blood cell transport in retinal microaneurysms\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Deep-PIV_ A new framework of PIV using deep learning techniques\\pdf_link_result.xls to cai_teacher_articles\\Deep-PIV_ A new framework of PIV using deep learning techniques\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\DeepM&Mnet_ Inferring the electroconvection multiphysics fields based on operator approximation by neural networks\\pdf_link_result.xls to cai_teacher_articles\\DeepM&Mnet_ Inferring the electroconvection multiphysics fields based on operator approximation by neural networks\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\DeepPTV_ particle tracking velocimetry for complex flow motion via deep neural networks\\pdf_link_result.xls to cai_teacher_articles\\DeepPTV_ particle tracking velocimetry for complex flow motion via deep neural networks\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Dense motion estimation of particle images via a convolutional neural network\\pdf_link_result.xls to cai_teacher_articles\\Dense motion estimation of particle images via a convolutional neural network\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Dynamic illumination optical flow computing for sensing multiple mobile robots from a drone\\pdf_link_result.xls to cai_teacher_articles\\Dynamic illumination optical flow computing for sensing multiple mobile robots from a drone\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Ensemble-Variational methods in data assimilation\\pdf_link_result.xls to cai_teacher_articles\\Ensemble-Variational methods in data assimilation\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Filtering enhanced tomographic PIV reconstruction based on deep neural networks\\pdf_link_result.xls to cai_teacher_articles\\Filtering enhanced tomographic PIV reconstruction based on deep neural networks\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Flow over an espresso cup_ inferring 3-D velocity and pressure fields from tomographic background oriented Schlieren via physics-informed neural networks\\pdf_link_result.xls to cai_teacher_articles\\Flow over an espresso cup_ inferring 3-D velocity and pressure fields from tomographic background oriented Schlieren via physics-informed neural networks\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Forecasting solar-thermal systems performance under transient operation using a data-driven machine learning approach based on the deep operator network architecture\\pdf_link_result.xls to cai_teacher_articles\\Forecasting solar-thermal systems performance under transient operation using a data-driven machine learning approach based on the deep operator network architecture\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Heat transfer prediction with unknown thermal boundary conditions using physics-informed neural networks\\pdf_link_result.xls to cai_teacher_articles\\Heat transfer prediction with unknown thermal boundary conditions using physics-informed neural networks\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Motion estimation under location uncertainty for turbulent fluid flows\\pdf_link_result.xls to cai_teacher_articles\\Motion estimation under location uncertainty for turbulent fluid flows\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Neural observer with Lyapunov stability guarantee for uncertain nonlinear systems\\pdf_link_result.xls to cai_teacher_articles\\Neural observer with Lyapunov stability guarantee for uncertain nonlinear systems\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\NSFnets (Navier-Stokes flow nets)_ Physics-informed neural networks for the incompressible Navier-Stokes equations\\pdf_link_result.xls to cai_teacher_articles\\NSFnets (Navier-Stokes flow nets)_ Physics-informed neural networks for the incompressible Navier-Stokes equations\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Operator learning for predicting multiscale bubble growth dynamics\\pdf_link_result.xls to cai_teacher_articles\\Operator learning for predicting multiscale bubble growth dynamics\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Particle image velocimetry based on a deep learning motion estimator\\pdf_link_result.xls to cai_teacher_articles\\Particle image velocimetry based on a deep learning motion estimator\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Particle image velocimetry based on a deep neural network\\pdf_link_result.xls to cai_teacher_articles\\Particle image velocimetry based on a deep neural network\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Physics-informed neural networks (PINNs) for fluid mechanics_ A review\\pdf_link_result.xls to cai_teacher_articles\\Physics-informed neural networks (PINNs) for fluid mechanics_ A review\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Physics-informed neural networks for heat transfer problems\\pdf_link_result.xls to cai_teacher_articles\\Physics-informed neural networks for heat transfer problems\\pdf_link_result.xlsx\n",
      "Renamed cai_teacher_articles\\Recurrent graph optimal transport for learning 3D flow motion in particle tracking\\pdf_link_result.xls to cai_teacher_articles\\Recurrent graph optimal transport for learning 3D flow motion in particle tracking\\pdf_link_result.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 定义文件夹路径\n",
    "folder_path = 'cai_teacher_articles'\n",
    "\n",
    "# 遍历文件夹\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        # 找到所有 result.xlsx 文件\n",
    "        if file == 'pdf_link_result.xls':\n",
    "            # 构建 result.xlsx 的完整路径\n",
    "            result_file_path = os.path.join(root, file)\n",
    "            # 构建新的文件名 pdf_link_result.xlsx 的完整路径\n",
    "            new_file_name = os.path.join(root, 'pdf_link_result.xlsx')\n",
    "            # 重命名文件\n",
    "            shutil.move(result_file_path, new_file_name)\n",
    "            print(f\"Renamed {result_file_path} to {new_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('cai_teacher_articles','statisticalData.txt')\n",
    "with open(path,'a+',encoding='utf-8') as f:\n",
    "    f.write('hello\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 定义数据\n",
    "data = [\n",
    "    {\"Title\": \"Title 1\", \"Pdf link\": \"Link 1\"},\n",
    "    {\"Title\": \"Title 2\", \"Pdf link\": \"Link 2\"},\n",
    "    {\"Title\": \"Title 3\", \"Pdf link\": \"Link 3\"}\n",
    "]\n",
    "\n",
    "# 定义 CSV 文件路径\n",
    "csv_file_path = \"data.csv\"\n",
    "\n",
    "# 定义 CSV 文件的列名\n",
    "fields = [\"Title\", \"Pdf link\"]\n",
    "\n",
    "# 写入数据到 CSV 文件\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fields)\n",
    "    \n",
    "    # 写入列名\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # 写入数据\n",
    "    for item in data:\n",
    "        writer.writerow(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Title': 'A physics-informed variational DeepONet for predicting crack path in quasi-brittle materials',\n",
       "  'PDF Link': 'https://www.sciencedirect.com/science/article/am/pii/S004578252200010X'},\n",
       " {'Title': 'Physics-informed deep neural operator networks',\n",
       "  'PDF Link': 'https://www.researchgate.net/profile/Somdatta-Goswami/publication/374438071_Physics-Informed_Deep_Neural_Operator_Networks/links/6522de97b0df2f20a21d63b4/Physics-Informed-Deep-Neural-Operator-Networks.pdf'},\n",
       " {'Title': 'Interfacing finite elements with deep neural operators for fast multiscale modeling of mechanics problems',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2203.00003'},\n",
       " {'Title': 'Physics-informed neural operators',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2207.05748'},\n",
       " {'Title': 'Splitting physics-informed neural networks for inferring the dynamics of integer-and fractional-order neuron models',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2304.13205'},\n",
       " {'Title': 'Neural Operator: Learning Maps Between Function Spaces',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2108.08481'},\n",
       " {'Title': 'Neural implicit flow: a mesh-agnostic dimensionality reduction paradigm of spatio-temporal data',\n",
       "  'PDF Link': 'https://www.jmlr.org/papers/volume24/22-0365/22-0365.pdf'},\n",
       " {'Title': 'Multifidelity deep neural operators for efficient learning of partial differential equations with application to fast inverse design of nanoscale heat transport',\n",
       "  'PDF Link': 'https://link.aps.org/pdf/10.1103/PhysRevResearch.4.023210'},\n",
       " {'Title': 'Global, regional and national burden of bladder cancer and its attributable risk factors in 204 countries and territories, 1990–2019: a systematic analysis for the Global Burden of Disease study 2019',\n",
       "  'PDF Link': 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8634015/'},\n",
       " {'Title': 'The cost-accuracy trade-off in operator learning with neural networks',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2203.13181'},\n",
       " {'Title': 'Physics-informed machine learning: A survey on problems, methods and applications',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2211.08064'},\n",
       " {'Title': 'NUNO: A General Framework for Learning Parametric PDEs with Non-Uniform Data',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2305.18694'},\n",
       " {'Title': 'PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2306.08827'},\n",
       " {'Title': 'Meta-Auto-Decoder for Solving Parametric Partial Differential Equations',\n",
       "  'PDF Link': 'https://proceedings.neurips.cc/paper_files/paper/2022/file/948552777302d3abf92415b1d7e9de70-Paper-Conference.pdf'},\n",
       " {'Title': 'Ditto: Diffusion-inspired temporal transformer operator',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2307.09072'},\n",
       " {'Title': 'A hybrid iterative numerical transferable solver (HINTS) for PDEs based on deep operator network and relaxation methods',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2208.13273'},\n",
       " {'Title': 'ViTO: Vision Transformer-Operator',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2303.08891'},\n",
       " {'Title': 'Exponential convergence of deep operator networks for elliptic partial differential equations',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2112.08125'},\n",
       " {'Title': 'Integral autoencoder network for discretization-invariant learning',\n",
       "  'PDF Link': 'https://www.jmlr.org/papers/volume23/22-0297/22-0297.pdf'},\n",
       " {'Title': 'Predictions of multi-scale vortex-induced vibrations based on a multi-fidelity data assimilation method',\n",
       "  'PDF Link': 'None'},\n",
       " {'Title': 'Towards Foundation Models for Scientific Machine Learning: Characterizing Scaling and Transfer Behavior',\n",
       "  'PDF Link': 'https://proceedings.neurips.cc/paper_files/paper/2023/file/e15790966a4a9d85d688635c88ee6d8a-Paper-Conference.pdf'},\n",
       " {'Title': 'Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2401.09516'},\n",
       " {'Title': 'Multi-Resolution Active Learning of Fourier Neural Operators',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2309.16971'},\n",
       " {'Title': 'Inferring electrochemical performance and parameters of Li-ion batteries based on deep operator networks',\n",
       "  'PDF Link': 'https://www.sciencedirect.com/science/article/pii/S2352152X2300573X'},\n",
       " {'Title': 'A deep complementary energy method for solid mechanics using minimum complementary energy principle',\n",
       "  'PDF Link': 'https://www.researchgate.net/profile/Yizheng_Wang10/publication/368973732_Dcm_Deep_Complementary_Energy_Method_Based_on_the_Principle_of_Minimum_Complementary_Energy/links/65588bb0b86a1d521bf2684e/Dcm-Deep-Complementary-Energy-Method-Based-on-the-Principle-of-Minimum-Complementary-Energy.pdf'},\n",
       " {'Title': 'Deep transfer operator learning for partial differential equations under conditional shift',\n",
       "  'PDF Link': 'https://arxiv.org/pdf/2204.09810'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\\A physics-informed variational DeepONet for predicting crack path in quasi-brittle materials.pdf\n",
      "temp\\Physics-informed deep neural operator networks.pdf\n",
      "temp\\Interfacing finite elements with deep neural operators for fast multiscale modeling of mechanics problems.pdf\n",
      "temp\\Physics-informed neural operators.pdf\n",
      "temp\\Splitting physics-informed neural networks for inferring the dynamics of integer-and fractional-order neuron models.pdf\n",
      "temp\\Neural Operator  Learning Maps Between Function Spaces.pdf\n",
      "temp\\Neural implicit flow  a mesh-agnostic dimensionality reduction paradigm of spatio-temporal data.pdf\n",
      "temp\\Multifidelity deep neural operators for efficient learning of partial differential equations with application to fast inverse design of nanoscale heat transport.pdf\n",
      "temp\\Global, regional and national burden of bladder cancer and its attributable risk factors in 204 countries and territories, 1990–2019  a systematic analysis for the Global Burden of Disease study 2019.pdf\n",
      "temp\\The cost-accuracy trade-off in operator learning with neural networks.pdf\n",
      "temp\\Physics-informed machine learning  A survey on problems, methods and applications.pdf\n",
      "temp\\NUNO  A General Framework for Learning Parametric PDEs with Non-Uniform Data.pdf\n",
      "temp\\PINNacle  A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs.pdf\n",
      "temp\\Meta-Auto-Decoder for Solving Parametric Partial Differential Equations.pdf\n",
      "temp\\Ditto  Diffusion-inspired temporal transformer operator.pdf\n",
      "temp\\A hybrid iterative numerical transferable solver (HINTS) for PDEs based on deep operator network and relaxation methods.pdf\n",
      "temp\\ViTO  Vision Transformer-Operator.pdf\n",
      "temp\\Exponential convergence of deep operator networks for elliptic partial differential equations.pdf\n",
      "temp\\Integral autoencoder network for discretization-invariant learning.pdf\n",
      "temp\\Predictions of multi-scale vortex-induced vibrations based on a multi-fidelity data assimilation method.pdf\n",
      "temp\\Towards Foundation Models for Scientific Machine Learning  Characterizing Scaling and Transfer Behavior.pdf\n",
      "temp\\Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling.pdf\n",
      "temp\\Multi-Resolution Active Learning of Fourier Neural Operators.pdf\n",
      "temp\\Inferring electrochemical performance and parameters of Li-ion batteries based on deep operator networks.pdf\n",
      "temp\\A deep complementary energy method for solid mechanics using minimum complementary energy principle.pdf\n",
      "temp\\Deep transfer operator learning for partial differential equations under conditional shift.pdf\n"
     ]
    }
   ],
   "source": [
    "def sanitize_filename(filename):\n",
    "    \"\"\"\n",
    "    清理文件名，移除或替换非法字符，并确保文件名长度不超过255字符。\n",
    "    \"\"\"\n",
    "    sanitized = filename.replace(':', ' ')\n",
    "    return sanitized[:255]\n",
    "\n",
    "\n",
    "for article in article_list:\n",
    "    # print(article['Title'])\n",
    "    path = 'temp'\n",
    "    filename = sanitize_filename(article['Title'])\n",
    "    savePath = os.path.join(path,filename+'.pdf')\n",
    "    print(savePath)\n",
    "    # print(path + filename + '.pdf')\n",
    "    # print(sanitize_filename(article['Title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始下载https://arxiv.org/pdf/2108.08481\n",
      "temp/Neural Operator: Learning Maps Between Function Spaces.pdf\n",
      "Sucessful to download /Neural Operator: Learning Maps Between Function Spaces\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'Title': 'Neural Operator: Learning Maps Between Function Spaces',\n",
    "  'PDF Link': 'https://arxiv.org/pdf/2108.08481'}\n",
    "\n",
    "PDFDownload.get_file(a,'temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 10, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12120\\469534565.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[1;31m# with open(os.path.join(root,log),'a+',encoding = 'utf-8') as f:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mcsv_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0marticle_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;31m# Check for duplicates in names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[0m_validate_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"names\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             )\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"index_col\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m         \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[0mconverters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"converters\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m             data, names = _process_date_conversion(\n\u001b[0;32m   1847\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_date_conv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 10, saw 4\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file == 'pdf_link_result.csv':\n",
    "            # with open(os.path.join(root,log),'a+',encoding = 'utf-8') as f:\n",
    "            csv_path = os.path.join(root,file)\n",
    "            df = pd.read_csv(csv_path)\n",
    "            article_list = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 2 fields in line 10, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12120\\1161018993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0marticle_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'records'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mPDFDownload\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticle_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;31m# Check for duplicates in names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[0m_validate_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"names\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             )\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"index_col\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m         \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[0mconverters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"converters\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m             data, names = _process_date_conversion(\n\u001b[0;32m   1847\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_date_conv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 2 fields in line 10, saw 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "path = r'cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\pdf_link_result.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "article_list = df.to_dict(orient='records')\n",
    "PDFDownload.get_file(article_list[0],'.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cai_teacher_articles\\\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data\\\\pdf_link_result.csv'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Initializing from file failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12120\\2056234115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# pd.read_csv(csv_path)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Extract some of the arguments (pass chunksize on).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"iterator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m     \u001b[0mchunksize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chunksize\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chunksize\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m     \"\"\"\n\u001b[1;32m--> 787\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m     \u001b[0mPassed\u001b[0m \u001b[0mdialect\u001b[0m \u001b[0moverrides\u001b[0m \u001b[0many\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mrelated\u001b[0m \u001b[0mparser\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_c_unsupported\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"python\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_python_unsupported\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\TitleQuest\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m                 \u001b[1;31m# general type inference and conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m                 cvals, na_count = self._infer_types(\n\u001b[0m\u001b[0;32m   1709\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_na_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mcol_na_fvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtry_num_bool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m                 )\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Initializing from file failed"
     ]
    }
   ],
   "source": [
    "# pd.read_csv(csv_path)\n",
    "pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data.txt\n",
      "26\n",
      "---------------------\n",
      "2 AOSLO-net_ a deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscopy images.txt\n",
      "2\n",
      "---------------------\n",
      "3 Artificial intelligence velocimetry and microaneurysm-on-a-chip for three-dimensional analysis of blood flow in physiology and disease.txt\n",
      "12\n",
      "---------------------\n",
      "4 Computational investigation of blood cell transport in retinal microaneurysms.txt\n",
      "5\n",
      "---------------------\n",
      "5 Deep-PIV_ A new framework of PIV using deep learning techniques.txt\n",
      "2\n",
      "---------------------\n",
      "6 DeepM&Mnet_ Inferring the electroconvection multiphysics fields based on operator approximation by neural networks.txt\n",
      "37\n",
      "---------------------\n",
      "7 DeepPTV_ particle tracking velocimetry for complex flow motion via deep neural networks.txt\n",
      "2\n",
      "---------------------\n",
      "8 Dense motion estimation of particle images via a convolutional neural network.txt\n",
      "18\n",
      "---------------------\n",
      "9 Dynamic illumination optical flow computing for sensing multiple mobile robots from a drone.txt\n",
      "6\n",
      "---------------------\n",
      "10 Ensemble-Variational methods in data assimilation.txt\n",
      "1\n",
      "---------------------\n",
      "11 Filtering enhanced tomographic PIV reconstruction based on deep neural networks.txt\n",
      "6\n",
      "---------------------\n",
      "12 Flow over an espresso cup_ inferring 3-D velocity and pressure fields from tomographic background oriented Schlieren via physics-informed neural networks.txt\n",
      "18\n",
      "---------------------\n",
      "13 Forecasting solar-thermal systems performance under transient operation using a data-driven machine learning approach based on the deep operator network architecture.txt\n",
      "7\n",
      "---------------------\n",
      "14 Heat transfer prediction with unknown thermal boundary conditions using physics-informed neural networks.txt\n",
      "3\n",
      "---------------------\n",
      "15 Motion estimation under location uncertainty for turbulent fluid flows.txt\n",
      "8\n",
      "---------------------\n",
      "16 Neural observer with Lyapunov stability guarantee for uncertain nonlinear systems.txt\n",
      "1\n",
      "---------------------\n",
      "17 NSFnets (Navier-Stokes flow nets)_ Physics-informed neural networks for the incompressible Navier-Stokes equations.txt\n",
      "58\n",
      "---------------------\n",
      "18 Operator learning for predicting multiscale bubble growth dynamics.txt\n",
      "18\n",
      "---------------------\n",
      "19 Particle image velocimetry based on a deep learning motion estimator.txt\n",
      "6\n",
      "---------------------\n",
      "20 Particle image velocimetry based on a deep neural network.txt\n",
      "2\n",
      "---------------------\n",
      "21 Physics-informed neural networks (PINNs) for fluid mechanics_ A review.txt\n",
      "64\n",
      "---------------------\n",
      "22 Physics-informed neural networks for heat transfer problems.txt\n",
      "40\n",
      "---------------------\n",
      "23 Recurrent graph optimal transport for learning 3D flow motion in particle tracking.txt\n",
      "5\n",
      "---------------------\n",
      "totalcnt : 347\n"
     ]
    }
   ],
   "source": [
    "import fileinput\n",
    "import os \n",
    "def count_lines_fileinput(filename):\n",
    "    return sum(1 for line in fileinput.input(filename))\n",
    "totalcnt = 0\n",
    "idx = 0\n",
    "for root,dirs,files in os.walk('cai_teacher_articles'):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            idx += 1\n",
    "            cnt = count_lines_fileinput(os.path.join(root,file))\n",
    "            totalcnt +=cnt\n",
    "            print(f\"{idx} {file}\\n{cnt}\")\n",
    "            print('---------------------')\n",
    "    \n",
    "print(f'totalcnt : {totalcnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以下标题没有对应的PDF文件：\n",
      "Splitting physics-informed neural networks for inferring the dynamics of integer-and fractional-order neuron models\n",
      "https://arxiv.org/pdf/2304.13205\n",
      "Multifidelity deep neural operators for efficient learning of partial differential equations with application to fast inverse design of nanoscale heat transport\n",
      "https://link.aps.org/pdf/10.1103/PhysRevResearch.4.023210\n",
      "Global, regional and national burden of bladder cancer and its attributable risk factors in 204 countries and territories, 1990–2019: a systematic analysis for the Global Burden of Disease study 2019\n",
      "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8634015/\n",
      "Ditto: Diffusion-inspired temporal transformer operator\n",
      "https://arxiv.org/html/2307.09072v2\n",
      "A hybrid iterative numerical transferable solver (HINTS) for PDEs based on deep operator network and relaxation methods\n",
      "https://arxiv.org/pdf/2208.13273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import os \n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"\n",
    "    清理文件名，移除或替换非法字符，并确保文件名长度不超过255字符。\n",
    "    \"\"\"\n",
    "    sanitized = filename.replace(':', ' ')\n",
    "    return sanitized[:255]\n",
    "\n",
    "\n",
    "path = r'cai_teacher_articles\\A comprehensive and fair comparison of two neural operators (with practical extensions) based on fair data'\n",
    "csv_path = os.path.join(path,'pdf_link_result.csv')\n",
    "\n",
    "# 读取CSV文件\n",
    "with open(csv_path, mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file, delimiter='#')\n",
    "    next(reader)  # 跳过标题行\n",
    "    missing_pdfs = []\n",
    "    missing_link = []\n",
    "    for row in reader:\n",
    "        title = row[0]\n",
    "        pdf_file = f\"{sanitize_filename(title)}.pdf\"\n",
    "        # print(pdf_file)\n",
    "        pdf_path = os.path.join(path,pdf_file)\n",
    "        # 检查PDF文件是否存在\n",
    "        if not os.path.isfile(pdf_path):\n",
    "            missing_pdfs.append(title)\n",
    "            missing_link.append(row[1])\n",
    "\n",
    "# 输出没有对应PDF的标题\n",
    "print(\"以下标题没有对应的PDF文件：\")\n",
    "for idx , title in enumerate (missing_pdfs):\n",
    "    print(f\"{title}\\n{missing_link[idx]}\")\n",
    "\n",
    "len(missing_pdfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Global, regional and national burden of bladder cancer and its attributable risk factors in 204 countries and territories, 1990–2019 a systematic analysis for the Global Burden of Disease study 2019'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sanitize_filename('Global, regional and national burden of bladder cancer and its attributable risk factors in 204 countries and territories, 1990–2019 a systematic analysis for the Global Burden of Disease study 2019')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TitleQuest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
